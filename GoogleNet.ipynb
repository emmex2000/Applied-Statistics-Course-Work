{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emmex2000/Applied-Statistics-Course-Work/blob/main/GoogleNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0StUUB6iIkgV",
        "outputId": "08fd5a87-bf53-4027-d68a-9c8f7b76b613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0-vhh3A__9j"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import urllib\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "% matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yfa4TDwt_lW5"
      },
      "outputs": [],
      "source": [
        "DIR = \"drive/MyDrive/Thorax Disease Classification\"\n",
        "os.chdir(DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWW-PYLgSddL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "71101ca9-2122-4eb5-b457-a4862cbaa72a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b6f448a0-a997-4309-a3c3-6ed066b57413\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image Index</th>\n",
              "      <th>Effusion</th>\n",
              "      <th>No Finding</th>\n",
              "      <th>Pneumonia</th>\n",
              "      <th>Pneumothorax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00006022_006.png</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00020953_001.png</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00029052_010.png</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00014125_054.png</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00016987_010.png</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6f448a0-a997-4309-a3c3-6ed066b57413')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b6f448a0-a997-4309-a3c3-6ed066b57413 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b6f448a0-a997-4309-a3c3-6ed066b57413');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        Image Index  Effusion  No Finding  Pneumonia  Pneumothorax\n",
              "0  00006022_006.png         0           1          0             0\n",
              "1  00020953_001.png         1           0          0             0\n",
              "2  00029052_010.png         1           0          0             1\n",
              "3  00014125_054.png         1           0          0             0\n",
              "4  00016987_010.png         1           0          0             0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df = pd.read_csv(\"df.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXsDvPTsSc_9"
      },
      "outputs": [],
      "source": [
        "## split data into train and test\n",
        "n_train = int(df.shape[0] * .7)\n",
        "train = df.iloc[:n_train]\n",
        "test = df.iloc[n_train:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqBx7UAVQy1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37fd64b2-616d-41c7-b9c4-5040c2b1bd87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Effusion', 'No Finding', 'Pneumonia', 'Pneumothorax']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "col = ['Effusion', 'No Finding', 'Pneumonia', 'Pneumothorax']\n",
        "col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALcb8PDuP_gw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K \n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DLspXX3ihd6"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255., validation_split=0.2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RW3yCU4irFr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "991f5d61-186e-4ed5-ddbb-3429ad97ec01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9354 validated image filenames.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 5988 invalid image filename(s) in x_col=\"Image Index\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ]
        }
      ],
      "source": [
        "train_generator = datagen.flow_from_dataframe(dataframe=train,\n",
        "                                            directory=\"data/images/\",\n",
        "                                            x_col=\"Image Index\",\n",
        "                                            y_col=col,\n",
        "                                            subset=\"training\",\n",
        "                                            batch_size=128,\n",
        "                                            seed=42,\n",
        "                                            shuffle=True,\n",
        "                                            class_mode=\"raw\",\n",
        "                                            target_size=(224, 224))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RcaKN8Hiq7v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aca348b8-1ca0-4ada-e5ce-c49bc5bfbb30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2338 validated image filenames.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 5986 invalid image filename(s) in x_col=\"Image Index\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ]
        }
      ],
      "source": [
        "valid_generator = datagen.flow_from_dataframe(dataframe=train,\n",
        "                                            directory=\"data/images/\",\n",
        "                                            x_col=\"Image Index\",\n",
        "                                            y_col=col,\n",
        "                                            subset=\"validation\",\n",
        "                                            batch_size=128,\n",
        "                                            seed=42,\n",
        "                                            shuffle=True,\n",
        "                                            class_mode=\"raw\",\n",
        "                                            target_size=(224, 224))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGAzw4E8iqvc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b30fea6-263a-46b6-b911-b96e0c707170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5016 validated image filenames.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 2562 invalid image filename(s) in x_col=\"Image Index\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "test_generator = test_datagen.flow_from_dataframe(dataframe=test,\n",
        "                                            directory=\"data/images/\",\n",
        "                                            x_col=\"Image Index\",\n",
        "                                            y_col=col,\n",
        "                                            batch_size=32,\n",
        "                                            seed=42,\n",
        "                                            shuffle=False,\n",
        "                                            class_mode=\"raw\",\n",
        "                                            target_size=(224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_label = test_generator.labels\n",
        "np.save(\"test_label.npy\", test_label)"
      ],
      "metadata": {
        "id": "SumEAR1mW3q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nn9uRNPcP_Iv"
      },
      "outputs": [],
      "source": [
        "# class_names = col\n",
        "\n",
        "# plt.figure(figsize=(10, 10))\n",
        "# for images, labels in train_generator.take(1):\n",
        "#   for i in range(9):\n",
        "#     ax = plt.subplot(3, 3, i + 1)\n",
        "#     plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "#     plt.title(class_names[labels[i]])\n",
        "#     plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceCsituIUkYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd720315-af07-4b2d-f803-58353e0af00d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "IMG_SHAPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyA6aFeTP9jx"
      },
      "outputs": [],
      "source": [
        "base_model = tf.keras.applications.InceptionV3(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2y0JNaBP9Bu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed25923-e47f-4e5a-bd2b-7c3b7ed855f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 111, 111, 32  864         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 111, 111, 32  96         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 111, 111, 32  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 109, 109, 32  9216        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 109, 109, 32  96         ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 109, 109, 32  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 109, 109, 64  18432       ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 109, 109, 64  192        ['conv2d_2[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 109, 109, 64  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 54, 54, 64)   0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 54, 54, 80)   5120        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 54, 54, 80)  240         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 54, 54, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 52, 52, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 52, 52, 192)  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 52, 52, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 25, 25, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 25, 25, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 25, 25, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 25, 25, 96)  288         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 25, 25, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 25, 25, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 25, 25, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 25, 25, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 25, 25, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 25, 25, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 25, 25, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 25, 25, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 25, 25, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 25, 25, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 25, 25, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 25, 25, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 25, 25, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 25, 25, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 25, 25, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 25, 25, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 25, 25, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 25, 25, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 25, 25, 64)  192         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 25, 25, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 25, 25, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 25, 25, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 25, 25, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 25, 25, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 25, 25, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 25, 25, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 25, 25, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 25, 25, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 25, 25, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 25, 25, 64)  192         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 25, 25, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 25, 25, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 25, 25, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 12, 12, 384)  995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 12, 12, 96)   82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 12, 12, 384)  1152       ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 12, 12, 96)  288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 12, 12, 384)  0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0          ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 12, 12, 768)  0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 12, 12, 128)  384        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 12, 12, 128)  384        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 12, 12, 128)  384        ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 12, 12, 128)  384        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 12, 12, 128)  384        ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 12, 12, 128)  384        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 12, 12, 768)  0          ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 12, 12, 192)  576        ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 12, 12, 192)  576        ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 12, 12, 192)  576        ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 12, 12, 192)  576        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 12, 12, 768)  0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 12, 12, 160)  480        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 12, 12, 160)  480        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 12, 12, 160)  480        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 12, 12, 160)  480        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 12, 12, 160)  480        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 12, 12, 160)  480        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 12, 12, 768)  0          ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 12, 12, 192)  576        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 12, 12, 192)  576        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 12, 12, 192)  576        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 12, 12, 192)  576        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 12, 12, 768)  0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 12, 12, 160)  480        ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 12, 12, 160)  480        ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 12, 12, 160)  480        ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 12, 12, 160)  480        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 12, 12, 160)  480        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 12, 12, 160)  480        ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 12, 12, 768)  0          ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 12, 12, 192)  576        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 12, 12, 192)  576        ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 12, 12, 192)  576        ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 12, 12, 192)  576        ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 12, 12, 768)  0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 12, 12, 192)  576        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 12, 12, 192)  576        ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 12, 12, 192)  576        ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 12, 12, 192)  576        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 12, 12, 192)  576        ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 12, 12, 192)  576        ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 12, 12, 768)  0          ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 12, 12, 192)  576        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 12, 12, 192)  576        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 12, 12, 192)  576        ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 12, 12, 192)  576        ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 12, 12, 768)  0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 12, 12, 192)  576        ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 12, 12, 192)  576        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 12, 12, 192)  576        ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 12, 12, 192)  576        ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 5, 5, 320)    552960      ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 5, 5, 192)    331776      ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 5, 5, 320)   960         ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 5, 5, 192)   576         ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)   0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)           (None, 5, 5, 1280)   0           ['activation_71[0][0]',          \n",
            "                                                                  'activation_75[0][0]',          \n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 5, 5, 448)    573440      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 5, 5, 384)    491520      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, 5, 5, 1280)  0           ['mixed8[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 5, 5, 320)    409600      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 5, 5, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 5, 5, 320)   960         ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 5, 5, 192)   576         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)         (None, 5, 5, 768)    0           ['activation_78[0][0]',          \n",
            "                                                                  'activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 5, 5, 768)    0           ['activation_82[0][0]',          \n",
            "                                                                  'activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)           (None, 5, 5, 2048)   0           ['activation_76[0][0]',          \n",
            "                                                                  'mixed9_0[0][0]',               \n",
            "                                                                  'concatenate[0][0]',            \n",
            "                                                                  'activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 5, 5, 448)    917504      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 5, 5, 384)    786432      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, 5, 5, 2048)  0           ['mixed9[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 5, 5, 320)    655360      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 5, 5, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 5, 5, 320)   960         ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 5, 5, 192)   576         ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)         (None, 5, 5, 768)    0           ['activation_87[0][0]',          \n",
            "                                                                  'activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 5, 5, 768)    0           ['activation_91[0][0]',          \n",
            "                                                                  'activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)          (None, 5, 5, 2048)   0           ['activation_85[0][0]',          \n",
            "                                                                  'mixed9_1[0][0]',               \n",
            "                                                                  'concatenate_1[0][0]',          \n",
            "                                                                  'activation_93[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Let's take a look at the base model architecture\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsO9fSceXQ7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6f8d647-5389-40e5-c03b-6aacac2a1900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 5, 5, 2048)\n"
          ]
        }
      ],
      "source": [
        "image_batch, label_batch = next(iter(train_generator))\n",
        "feature_batch = base_model(image_batch)\n",
        "print(feature_batch.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(feature_batch_average.shape)"
      ],
      "metadata": {
        "id": "oRh3dWPx7G4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a7cfb27-d743-4fba-973e-51ec9f85677f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvUykR8QScy0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c95d4173-ef7a-4423-875d-54d1418d4541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 4)\n"
          ]
        }
      ],
      "source": [
        "prediction_layer = tf.keras.layers.Dense(4, activation='softmax')\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWaGJdNYSck3"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFUQeQbDSct6"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.Input(shape=(IMG_SHAPE))\n",
        "x = base_model(inputs, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model = tf.keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JXogwDBScoy"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUfNtkP2ScfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42cb377b-1d82-4af1-a346-e4e79704e34d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of layers in the base model:  311\n"
          ]
        }
      ],
      "source": [
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 220\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Rs-hD_U6YmB"
      },
      "outputs": [],
      "source": [
        "model1 = keras.models.clone_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMXkyQNLSwvM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b616d4ff-3fcb-4547-b541-29017d11c24f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "#COMPILATION OF MODEL ARCHITECTURE\n",
        "\n",
        "base_learning_rate = 0.0001\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              optimizer = tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIrv1zZQcwQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45e58bd0-aa66-4211-bbe9-9b434f5b49dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " inception_v3 (Functional)   (None, 5, 5, 2048)        21802784  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 8196      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,810,980\n",
            "Trainable params: 12,820,868\n",
            "Non-trainable params: 8,990,112\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qyutxnn1cwEa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ccfc0c-9285-4a6c-b6b2-1fb07345e70b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "len(model.trainable_variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvEnRMmTcv3P"
      },
      "outputs": [],
      "source": [
        "# custom loss\n",
        "\n",
        "POS_WEIGHT = 10  # multiplier for positive targets, needs to be tuned\n",
        "\n",
        "\n",
        "def wce(target, output):\n",
        "    \"\"\"\n",
        "    Weighted binary crossentropy between an output tensor \n",
        "    and a target tensor. POS_WEIGHT is used as a multiplier \n",
        "    for the positive targets.\n",
        "\n",
        "    Combination of the following functions:\n",
        "    * keras.losses.binary_crossentropy\n",
        "    * keras.backend.tensorflow_backend.binary_crossentropy\n",
        "    * tf.nn.weighted_cross_entropy_with_logits\n",
        "    \"\"\"\n",
        "    # print(f\"target: {target}\")\n",
        "    # print(f\"output: {output}\")\n",
        "    # transform back to logits\n",
        "    output = K.clip(output, K.epsilon(), 1 - K.epsilon())\n",
        "    output = tf.math.log(output / (1 - output))\n",
        "\n",
        "    # output = tf.constant(output)\n",
        "    # target = tf.constant(target)\n",
        "    labels = tf.cast(tf.reshape(target , [-1, 4]), dtype=tf.float32)\n",
        "\n",
        "    # compute weighted loss\n",
        "    loss = tf.nn.weighted_cross_entropy_with_logits(labels=labels,\n",
        "                                                    logits=output,\n",
        "                                                    pos_weight=POS_WEIGHT)\n",
        "   # loss = tf.where(tf.is_nan(loss), tf.zeros_like(loss), loss)\n",
        "    return K.mean(loss)\n",
        "\n",
        "# def wce(target, output):\n",
        "   \n",
        "#     # transform back to logits\n",
        "#     output = K.clip(output, K.epsilon(), 1 - K.epsilon())\n",
        "#     output = tf.math.log(output / (1 - output))\n",
        "\n",
        "#     # output = tf.constant(output)\n",
        "#     # target = tf.constant(target)\n",
        "#     labels = tf.cast(tf.reshape(target , [-1, 4]), dtype=tf.float32)\n",
        "\n",
        "#     # compute weighted loss\n",
        "#     loss = tf.reduced_mean(tf.nn.weighted_cross_entropy_with_logits(labels=labels, logits=output, pos_weight=POS_WEIGHT))\n",
        "#     return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hz9WTQY1cvq4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbv1wxrfcvdg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d84b7102-e80f-40b9-969e-89d2f5ebbf0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anqsIG-8SwVs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8193dc2-a846-42d5-d966-b3e85eda1d6e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "73/73 [==============================] - 225s 3s/step - loss: 0.4535 - accuracy: 0.5983 - val_loss: 0.4144 - val_accuracy: 0.6445\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 253s 3s/step - loss: 0.3982 - accuracy: 0.6607 - val_loss: 0.4028 - val_accuracy: 0.6602\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 250s 3s/step - loss: 0.3590 - accuracy: 0.6994 - val_loss: 0.3924 - val_accuracy: 0.6758\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 208s 3s/step - loss: 0.3007 - accuracy: 0.7590 - val_loss: 0.4373 - val_accuracy: 0.6372\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 207s 3s/step - loss: 0.2356 - accuracy: 0.8079 - val_loss: 0.4286 - val_accuracy: 0.6701\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 207s 3s/step - loss: 0.1566 - accuracy: 0.8795 - val_loss: 0.5943 - val_accuracy: 0.6766\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 209s 3s/step - loss: 0.1019 - accuracy: 0.9241 - val_loss: 0.6109 - val_accuracy: 0.6654\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 206s 3s/step - loss: 0.0576 - accuracy: 0.9521 - val_loss: 0.8405 - val_accuracy: 0.6649\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 206s 3s/step - loss: 0.0354 - accuracy: 0.9684 - val_loss: 0.8542 - val_accuracy: 0.6359\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 205s 3s/step - loss: 0.0361 - accuracy: 0.9641 - val_loss: 0.8558 - val_accuracy: 0.6493\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 203s 3s/step - loss: 0.0185 - accuracy: 0.9698 - val_loss: 1.0805 - val_accuracy: 0.6749\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 203s 3s/step - loss: 0.0110 - accuracy: 0.9748 - val_loss: 1.0955 - val_accuracy: 0.6445\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 200s 3s/step - loss: 0.0555 - accuracy: 0.9517 - val_loss: 0.8749 - val_accuracy: 0.6528\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 202s 3s/step - loss: 0.0104 - accuracy: 0.9730 - val_loss: 1.0402 - val_accuracy: 0.6636\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 200s 3s/step - loss: 0.0047 - accuracy: 0.9761 - val_loss: 1.1613 - val_accuracy: 0.6662\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 199s 3s/step - loss: 0.0033 - accuracy: 0.9779 - val_loss: 1.1799 - val_accuracy: 0.6636\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 195s 3s/step - loss: 0.0017 - accuracy: 0.9751 - val_loss: 1.3678 - val_accuracy: 0.6780\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 196s 3s/step - loss: 0.0013 - accuracy: 0.9772 - val_loss: 1.4341 - val_accuracy: 0.6766\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 196s 3s/step - loss: 0.0021 - accuracy: 0.9770 - val_loss: 1.2824 - val_accuracy: 0.6675\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 196s 3s/step - loss: 0.0029 - accuracy: 0.9775 - val_loss: 1.2957 - val_accuracy: 0.6580\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 196s 3s/step - loss: 0.0137 - accuracy: 0.9720 - val_loss: 1.2176 - val_accuracy: 0.6654\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 196s 3s/step - loss: 0.0394 - accuracy: 0.9626 - val_loss: 1.0227 - val_accuracy: 0.6419\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 197s 3s/step - loss: 0.0116 - accuracy: 0.9735 - val_loss: 1.2109 - val_accuracy: 0.6541\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 197s 3s/step - loss: 0.0105 - accuracy: 0.9708 - val_loss: 1.1929 - val_accuracy: 0.6866\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 196s 3s/step - loss: 0.0182 - accuracy: 0.9659 - val_loss: 1.4815 - val_accuracy: 0.6597\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 196s 3s/step - loss: 0.0165 - accuracy: 0.9686 - val_loss: 1.0399 - val_accuracy: 0.6675\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 198s 3s/step - loss: 0.0080 - accuracy: 0.9746 - val_loss: 1.1100 - val_accuracy: 0.6385\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 194s 3s/step - loss: 0.0063 - accuracy: 0.9735 - val_loss: 1.3549 - val_accuracy: 0.6680\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 194s 3s/step - loss: 0.0018 - accuracy: 0.9751 - val_loss: 1.3648 - val_accuracy: 0.6688\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 194s 3s/step - loss: 7.5290e-04 - accuracy: 0.9761 - val_loss: 1.4607 - val_accuracy: 0.6762\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 198s 3s/step - loss: 6.7127e-04 - accuracy: 0.9753 - val_loss: 1.5394 - val_accuracy: 0.6736\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 195s 3s/step - loss: 1.3214e-04 - accuracy: 0.9724 - val_loss: 1.6413 - val_accuracy: 0.6771\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 194s 3s/step - loss: 6.4811e-05 - accuracy: 0.9739 - val_loss: 1.6628 - val_accuracy: 0.6753\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 189s 3s/step - loss: 4.6250e-05 - accuracy: 0.9710 - val_loss: 1.6869 - val_accuracy: 0.6749\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 193s 3s/step - loss: 3.7045e-05 - accuracy: 0.9739 - val_loss: 1.7236 - val_accuracy: 0.6775\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 190s 3s/step - loss: 3.1848e-05 - accuracy: 0.9727 - val_loss: 1.7487 - val_accuracy: 0.6758\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 193s 3s/step - loss: 2.6376e-05 - accuracy: 0.9745 - val_loss: 1.7763 - val_accuracy: 0.6810\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 198s 3s/step - loss: 2.2859e-05 - accuracy: 0.9743 - val_loss: 1.7910 - val_accuracy: 0.6766\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 190s 3s/step - loss: 2.1873e-05 - accuracy: 0.9725 - val_loss: 1.8070 - val_accuracy: 0.6801\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 194s 3s/step - loss: 1.7897e-05 - accuracy: 0.9737 - val_loss: 1.8164 - val_accuracy: 0.6832\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 194s 3s/step - loss: 1.8454e-05 - accuracy: 0.9738 - val_loss: 1.8524 - val_accuracy: 0.6814\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 196s 3s/step - loss: 1.4160e-05 - accuracy: 0.9738 - val_loss: 1.8527 - val_accuracy: 0.6845\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 197s 3s/step - loss: 1.5688e-05 - accuracy: 0.9745 - val_loss: 1.8950 - val_accuracy: 0.6784\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 195s 3s/step - loss: 1.3825e-05 - accuracy: 0.9770 - val_loss: 1.8857 - val_accuracy: 0.6814\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 193s 3s/step - loss: 1.2304e-05 - accuracy: 0.9756 - val_loss: 1.8987 - val_accuracy: 0.6797\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 193s 3s/step - loss: 1.1553e-05 - accuracy: 0.9736 - val_loss: 1.9115 - val_accuracy: 0.6827\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 194s 3s/step - loss: 1.1401e-05 - accuracy: 0.9744 - val_loss: 1.9087 - val_accuracy: 0.6819\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 195s 3s/step - loss: 9.1822e-06 - accuracy: 0.9730 - val_loss: 1.9503 - val_accuracy: 0.6771\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 191s 3s/step - loss: 8.5672e-06 - accuracy: 0.9724 - val_loss: 1.9492 - val_accuracy: 0.6784\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 200s 3s/step - loss: 7.9062e-06 - accuracy: 0.9733 - val_loss: 1.9614 - val_accuracy: 0.6832\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 196s 3s/step - loss: 6.9536e-06 - accuracy: 0.9749 - val_loss: 1.9764 - val_accuracy: 0.6819\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 198s 3s/step - loss: 8.7498e-06 - accuracy: 0.9741 - val_loss: 1.9883 - val_accuracy: 0.6814\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 191s 3s/step - loss: 7.3876e-06 - accuracy: 0.9731 - val_loss: 1.9799 - val_accuracy: 0.6819\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 192s 3s/step - loss: 6.4714e-06 - accuracy: 0.9732 - val_loss: 2.0041 - val_accuracy: 0.6784\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 191s 3s/step - loss: 5.6534e-06 - accuracy: 0.9727 - val_loss: 2.0115 - val_accuracy: 0.6814\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 197s 3s/step - loss: 5.0215e-06 - accuracy: 0.9749 - val_loss: 2.0437 - val_accuracy: 0.6788\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 193s 3s/step - loss: 5.3701e-06 - accuracy: 0.9751 - val_loss: 2.0289 - val_accuracy: 0.6784\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 194s 3s/step - loss: 4.9270e-06 - accuracy: 0.9746 - val_loss: 2.0466 - val_accuracy: 0.6810\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 197s 3s/step - loss: 1.2668e-05 - accuracy: 0.9766 - val_loss: 2.0540 - val_accuracy: 0.6853\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 196s 3s/step - loss: 5.2557e-06 - accuracy: 0.9723 - val_loss: 2.0581 - val_accuracy: 0.6840\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 197s 3s/step - loss: 4.6394e-06 - accuracy: 0.9744 - val_loss: 2.0879 - val_accuracy: 0.6840\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 195s 3s/step - loss: 4.9932e-06 - accuracy: 0.9764 - val_loss: 2.0755 - val_accuracy: 0.6853\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 196s 3s/step - loss: 4.9504e-06 - accuracy: 0.9731 - val_loss: 2.0800 - val_accuracy: 0.6840\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 196s 3s/step - loss: 3.5628e-06 - accuracy: 0.9758 - val_loss: 2.1116 - val_accuracy: 0.6832\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 197s 3s/step - loss: 4.5442e-06 - accuracy: 0.9756 - val_loss: 2.1373 - val_accuracy: 0.6840\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 193s 3s/step - loss: 3.5081e-06 - accuracy: 0.9742 - val_loss: 2.1223 - val_accuracy: 0.6849\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 189s 3s/step - loss: 2.9259e-06 - accuracy: 0.9756 - val_loss: 2.1392 - val_accuracy: 0.6819\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 194s 3s/step - loss: 3.2424e-06 - accuracy: 0.9744 - val_loss: 2.1298 - val_accuracy: 0.6840\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 190s 3s/step - loss: 3.3731e-06 - accuracy: 0.9759 - val_loss: 2.1548 - val_accuracy: 0.6819\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 193s 3s/step - loss: 3.3256e-06 - accuracy: 0.9774 - val_loss: 2.1464 - val_accuracy: 0.6788\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 189s 3s/step - loss: 2.7593e-06 - accuracy: 0.9763 - val_loss: 2.1744 - val_accuracy: 0.6810\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 193s 3s/step - loss: 2.4962e-06 - accuracy: 0.9751 - val_loss: 2.1505 - val_accuracy: 0.6836\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 193s 3s/step - loss: 2.1293e-06 - accuracy: 0.9751 - val_loss: 2.1781 - val_accuracy: 0.6814\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 200s 3s/step - loss: 3.1344e-06 - accuracy: 0.9750 - val_loss: 2.1882 - val_accuracy: 0.6875\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 197s 3s/step - loss: 2.3844e-06 - accuracy: 0.9749 - val_loss: 2.1595 - val_accuracy: 0.6827\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 198s 3s/step - loss: 2.5957e-06 - accuracy: 0.9739 - val_loss: 2.2067 - val_accuracy: 0.6801\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 196s 3s/step - loss: 2.1176e-06 - accuracy: 0.9781 - val_loss: 2.2248 - val_accuracy: 0.6819\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 197s 3s/step - loss: 2.8863e-06 - accuracy: 0.9761 - val_loss: 2.2808 - val_accuracy: 0.6819\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 200s 3s/step - loss: 1.9297e-06 - accuracy: 0.9769 - val_loss: 2.2723 - val_accuracy: 0.6836\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 190s 3s/step - loss: 1.9103e-06 - accuracy: 0.9761 - val_loss: 2.2469 - val_accuracy: 0.6823\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 189s 3s/step - loss: 1.9225e-06 - accuracy: 0.9756 - val_loss: 2.2590 - val_accuracy: 0.6784\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 190s 3s/step - loss: 1.8824e-06 - accuracy: 0.9755 - val_loss: 2.2457 - val_accuracy: 0.6801\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 187s 3s/step - loss: 1.3903e-06 - accuracy: 0.9746 - val_loss: 2.2552 - val_accuracy: 0.6827\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 188s 3s/step - loss: 1.5729e-06 - accuracy: 0.9762 - val_loss: 2.2796 - val_accuracy: 0.6819\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 189s 3s/step - loss: 1.8806e-06 - accuracy: 0.9776 - val_loss: 2.3235 - val_accuracy: 0.6793\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 190s 3s/step - loss: 2.0614e-06 - accuracy: 0.9771 - val_loss: 2.2952 - val_accuracy: 0.6840\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 190s 3s/step - loss: 1.6866e-06 - accuracy: 0.9775 - val_loss: 2.3225 - val_accuracy: 0.6784\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 187s 3s/step - loss: 1.2029e-06 - accuracy: 0.9761 - val_loss: 2.2875 - val_accuracy: 0.6862\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 184s 3s/step - loss: 1.0742e-06 - accuracy: 0.9751 - val_loss: 2.2910 - val_accuracy: 0.6832\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 189s 3s/step - loss: 1.0825e-06 - accuracy: 0.9750 - val_loss: 2.3089 - val_accuracy: 0.6814\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 190s 3s/step - loss: 1.2483e-06 - accuracy: 0.9748 - val_loss: 2.3510 - val_accuracy: 0.6810\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 185s 3s/step - loss: 9.2927e-07 - accuracy: 0.9761 - val_loss: 2.3511 - val_accuracy: 0.6814\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 184s 3s/step - loss: 1.0118e-06 - accuracy: 0.9751 - val_loss: 2.3602 - val_accuracy: 0.6801\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 189s 3s/step - loss: 1.0449e-06 - accuracy: 0.9769 - val_loss: 2.3478 - val_accuracy: 0.6819\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 189s 3s/step - loss: 1.0637e-06 - accuracy: 0.9757 - val_loss: 2.3985 - val_accuracy: 0.6801\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 190s 3s/step - loss: 9.4983e-07 - accuracy: 0.9757 - val_loss: 2.4137 - val_accuracy: 0.6806\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 8.8393e-07 - accuracy: 0.9770Epoch 98/100\n",
            "73/73 [==============================] - 185s 3s/step - loss: 7.2168e-07 - accuracy: 0.9763 - val_loss: 2.3708 - val_accuracy: 0.6806\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 184s 3s/step - loss: 7.2019e-07 - accuracy: 0.9752 - val_loss: 2.3864 - val_accuracy: 0.6801\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 186s 3s/step - loss: 8.1952e-07 - accuracy: 0.9744 - val_loss: 2.3718 - val_accuracy: 0.6823\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2de603ee50>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# #AFTER COMPILING THE MODEL, THE MODEL IS TRAINED BELOW\n",
        "callbacks = [\n",
        "    # tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True,),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs/GoogleNetlog' , histogram_freq=1),\n",
        "    # tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=3, verbose=1, min_delta=0.0001, min_lr=0, ),\n",
        "    \n",
        "]\n",
        "#AFTER COMPILING THE MODEL, THE MODEL IS TRAINED BELOW\n",
        "\n",
        "\n",
        "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n",
        "STEP_SIZE_TEST = test_generator.n//test_generator.batch_size\n",
        "\n",
        "model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,  validation_steps=STEP_SIZE_VALID, \n",
        "                    epochs=100, verbose=1, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jeO54xD68TS"
      },
      "outputs": [],
      "source": [
        "model.save(\"models/GoogleNet-model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXjFzE4ZS1Tk"
      },
      "outputs": [],
      "source": [
        "test_label = test_generator.labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7J1thiaoRv2X"
      },
      "outputs": [],
      "source": [
        "new_model = keras.models.load_model(\"models/GoogleNet-model.h5\", compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTuWiWjHRvtH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98a26d6f-15fd-4c5a-c5e1-5dd38d3b3a4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0000000e+00, 4.6011751e-34, 1.4752118e-30, 1.0055566e-33],\n",
              "       [2.7017584e-03, 1.2122653e-02, 9.8321491e-01, 1.9606359e-03],\n",
              "       [7.7074550e-20, 1.8491099e-22, 4.7596230e-24, 1.0000000e+00],\n",
              "       ...,\n",
              "       [2.9955108e-22, 1.0000000e+00, 6.3030504e-23, 6.8255134e-19],\n",
              "       [1.0000000e+00, 6.3159801e-29, 3.3071547e-20, 1.5174747e-26],\n",
              "       [1.0000000e+00, 3.8357822e-27, 1.2970562e-23, 3.5248186e-33]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "prob = new_model.predict_generator(test_generator)\n",
        "prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFTgYlpkTGOV"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eflFChICThzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1457385e-3ea3-4352-ef10-9242ca3c572b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7498533880062219"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "\n",
        "roc_auc_score(test_label, prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqn5xkQOS70H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad01f5f9-27f1-4952-e4d6-84627774dfe7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.798897227924032"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "roc_auc_score(test_label[:, 0], prob[:, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHB5Jy3NS7sP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87e76e97-07dd-43d9-a79e-25a010e9d521"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8197661476780794"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "roc_auc_score(test_label[:, 1], prob[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qicknDYqS7lK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ee188ba-70dd-4f56-8e1e-1f77a3419a5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5985546056855378"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "roc_auc_score(test_label[:, 2], prob[:, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz5vlXivS7fH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc730947-3581-4e97-b3e6-d4b6f1302dd5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7821955707372384"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "roc_auc_score(test_label[:, 3], prob[:, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XY5PouYnRvmn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDB_qQJk68Mj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85518b04-576e-4c90-f870-b37c05f1eb24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "base_learning_rate = 0.0001\n",
        "model1.compile(loss=wce,\n",
        "               optimizer = tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
        "               metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrL3Nzrv68D1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d1db070-38ab-4db4-e374-8e270d8e6e31"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "73/73 [==============================] - 209s 3s/step - loss: 3.3659 - accuracy: 0.5143 - val_loss: 3.2696 - val_accuracy: 0.5252\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 197s 3s/step - loss: 3.2596 - accuracy: 0.5189 - val_loss: 3.2643 - val_accuracy: 0.5247\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 195s 3s/step - loss: 3.2580 - accuracy: 0.5183 - val_loss: 3.2690 - val_accuracy: 0.5234\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 193s 3s/step - loss: 3.2554 - accuracy: 0.5197 - val_loss: 3.2787 - val_accuracy: 0.5213\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 193s 3s/step - loss: 3.2572 - accuracy: 0.5185 - val_loss: 3.2800 - val_accuracy: 0.5221\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 194s 3s/step - loss: 3.2550 - accuracy: 0.5189 - val_loss: 3.2742 - val_accuracy: 0.5230\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 196s 3s/step - loss: 3.2541 - accuracy: 0.5166 - val_loss: 3.2862 - val_accuracy: 0.5221\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 191s 3s/step - loss: 3.2656 - accuracy: 0.5180 - val_loss: 3.2709 - val_accuracy: 0.5221\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 193s 3s/step - loss: 3.2590 - accuracy: 0.5176 - val_loss: 3.2767 - val_accuracy: 0.5230\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 187s 3s/step - loss: 3.2595 - accuracy: 0.5172 - val_loss: 3.2691 - val_accuracy: 0.5208\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 193s 3s/step - loss: 3.2570 - accuracy: 0.5176 - val_loss: 3.2723 - val_accuracy: 0.5221\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 189s 3s/step - loss: 3.2554 - accuracy: 0.5184 - val_loss: 3.2671 - val_accuracy: 0.5234\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 187s 3s/step - loss: 3.2595 - accuracy: 0.5179 - val_loss: 3.2685 - val_accuracy: 0.5217\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 189s 3s/step - loss: 3.2542 - accuracy: 0.5184 - val_loss: 3.2712 - val_accuracy: 0.5221\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 188s 3s/step - loss: 3.2581 - accuracy: 0.5178 - val_loss: 3.2698 - val_accuracy: 0.5226\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 185s 3s/step - loss: 3.2513 - accuracy: 0.5180 - val_loss: 3.2711 - val_accuracy: 0.5230\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 188s 3s/step - loss: 3.2530 - accuracy: 0.5186 - val_loss: 3.2700 - val_accuracy: 0.5213\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 184s 3s/step - loss: 3.2528 - accuracy: 0.5182 - val_loss: 3.2700 - val_accuracy: 0.5226\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 186s 3s/step - loss: 3.2563 - accuracy: 0.5177 - val_loss: 3.2714 - val_accuracy: 0.5226\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 187s 3s/step - loss: 3.2555 - accuracy: 0.5173 - val_loss: 3.2628 - val_accuracy: 0.5234\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 187s 3s/step - loss: 3.2587 - accuracy: 0.5178 - val_loss: 3.2724 - val_accuracy: 0.5221\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 185s 3s/step - loss: 3.2592 - accuracy: 0.5166 - val_loss: 3.2691 - val_accuracy: 0.5230\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 188s 3s/step - loss: 3.2532 - accuracy: 0.5185 - val_loss: 3.2671 - val_accuracy: 0.5226\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 183s 3s/step - loss: 3.2575 - accuracy: 0.5177 - val_loss: 3.2714 - val_accuracy: 0.5221\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 186s 3s/step - loss: 3.2507 - accuracy: 0.5185 - val_loss: 3.2682 - val_accuracy: 0.5239\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 187s 3s/step - loss: 3.2462 - accuracy: 0.5190 - val_loss: 3.2624 - val_accuracy: 0.5217\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 184s 3s/step - loss: 3.2448 - accuracy: 0.5186 - val_loss: 3.2431 - val_accuracy: 0.5230\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 185s 3s/step - loss: 3.2142 - accuracy: 0.5177 - val_loss: 3.2395 - val_accuracy: 0.5226\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 184s 3s/step - loss: 3.2215 - accuracy: 0.5184 - val_loss: 3.2527 - val_accuracy: 0.5243\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 184s 3s/step - loss: 3.2062 - accuracy: 0.5170 - val_loss: 3.2146 - val_accuracy: 0.5221\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 186s 3s/step - loss: 3.1668 - accuracy: 0.5289 - val_loss: 3.1912 - val_accuracy: 0.5512\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 184s 3s/step - loss: 3.1278 - accuracy: 0.5416 - val_loss: 3.1077 - val_accuracy: 0.5616\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 184s 3s/step - loss: 3.0982 - accuracy: 0.5569 - val_loss: 3.0973 - val_accuracy: 0.5660\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 181s 2s/step - loss: 3.0950 - accuracy: 0.5581 - val_loss: 3.0974 - val_accuracy: 0.5677\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 181s 2s/step - loss: 3.0735 - accuracy: 0.5605 - val_loss: 3.0876 - val_accuracy: 0.5742\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 182s 3s/step - loss: 3.0558 - accuracy: 0.5669 - val_loss: 3.0897 - val_accuracy: 0.5764\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 183s 3s/step - loss: 3.0414 - accuracy: 0.5697 - val_loss: 3.1018 - val_accuracy: 0.5712\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 3.0556 - accuracy: 0.5685 - val_loss: 3.0642 - val_accuracy: 0.5786\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 3.0485 - accuracy: 0.5714 - val_loss: 3.1096 - val_accuracy: 0.5603\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 181s 2s/step - loss: 3.0308 - accuracy: 0.5716 - val_loss: 3.0786 - val_accuracy: 0.5751\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 3.0527 - accuracy: 0.5683 - val_loss: 3.0527 - val_accuracy: 0.5825\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 184s 3s/step - loss: 3.0171 - accuracy: 0.5760 - val_loss: 3.0383 - val_accuracy: 0.5855\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 182s 3s/step - loss: 3.0113 - accuracy: 0.5776 - val_loss: 3.0399 - val_accuracy: 0.5859\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 3.0135 - accuracy: 0.5780 - val_loss: 3.0625 - val_accuracy: 0.5877\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 3.0054 - accuracy: 0.5803 - val_loss: 3.0302 - val_accuracy: 0.5890\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 2.9845 - accuracy: 0.5862 - val_loss: 3.0289 - val_accuracy: 0.5872\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 183s 3s/step - loss: 2.9892 - accuracy: 0.5869 - val_loss: 3.0352 - val_accuracy: 0.5846\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 183s 3s/step - loss: 2.9724 - accuracy: 0.5859 - val_loss: 3.0166 - val_accuracy: 0.5890\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 2.9783 - accuracy: 0.5891 - val_loss: 3.0887 - val_accuracy: 0.5694\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 3.0025 - accuracy: 0.5826 - val_loss: 3.0345 - val_accuracy: 0.5816\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 180s 2s/step - loss: 2.9843 - accuracy: 0.5858 - val_loss: 3.0412 - val_accuracy: 0.5786\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 181s 2s/step - loss: 2.9701 - accuracy: 0.5896 - val_loss: 3.0115 - val_accuracy: 0.5972\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 2.9499 - accuracy: 0.5888 - val_loss: 3.0028 - val_accuracy: 0.5955\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 181s 2s/step - loss: 2.9535 - accuracy: 0.5924 - val_loss: 3.0022 - val_accuracy: 0.5911\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 2.9300 - accuracy: 0.5960 - val_loss: 2.9910 - val_accuracy: 0.5903\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 2.9363 - accuracy: 0.5936 - val_loss: 2.9873 - val_accuracy: 0.5955\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 181s 2s/step - loss: 2.9576 - accuracy: 0.5931 - val_loss: 3.0665 - val_accuracy: 0.5668\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 183s 3s/step - loss: 2.9638 - accuracy: 0.5863 - val_loss: 3.0620 - val_accuracy: 0.5812\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 181s 3s/step - loss: 2.9503 - accuracy: 0.5889 - val_loss: 2.9928 - val_accuracy: 0.5868\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 2.9342 - accuracy: 0.5945 - val_loss: 2.9825 - val_accuracy: 0.5972\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 181s 2s/step - loss: 2.9155 - accuracy: 0.5969 - val_loss: 2.9875 - val_accuracy: 0.5972\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 186s 3s/step - loss: 2.9138 - accuracy: 0.5962 - val_loss: 3.0179 - val_accuracy: 0.5946\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 183s 3s/step - loss: 2.9197 - accuracy: 0.5976 - val_loss: 3.0319 - val_accuracy: 0.5807\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 183s 3s/step - loss: 2.9142 - accuracy: 0.5958 - val_loss: 2.9724 - val_accuracy: 0.5955\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 2.9050 - accuracy: 0.5964 - val_loss: 2.9781 - val_accuracy: 0.5938\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 2.9061 - accuracy: 0.5950 - val_loss: 2.9677 - val_accuracy: 0.5972\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 2.9080 - accuracy: 0.5983 - val_loss: 2.9830 - val_accuracy: 0.5916\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 183s 3s/step - loss: 2.9109 - accuracy: 0.5958 - val_loss: 2.9775 - val_accuracy: 0.5920\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 184s 3s/step - loss: 2.8956 - accuracy: 0.6007 - val_loss: 2.9898 - val_accuracy: 0.5916\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 183s 3s/step - loss: 2.8848 - accuracy: 0.5986 - val_loss: 2.9644 - val_accuracy: 0.5964\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 184s 3s/step - loss: 2.8749 - accuracy: 0.6034 - val_loss: 3.0162 - val_accuracy: 0.5846\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 181s 2s/step - loss: 2.9000 - accuracy: 0.5968 - val_loss: 2.9537 - val_accuracy: 0.5929\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 180s 2s/step - loss: 2.8828 - accuracy: 0.6000 - val_loss: 2.9383 - val_accuracy: 0.6016\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 2.8634 - accuracy: 0.6063 - val_loss: 2.9733 - val_accuracy: 0.5964\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 183s 3s/step - loss: 2.8795 - accuracy: 0.6025 - val_loss: 2.9871 - val_accuracy: 0.5951\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 181s 2s/step - loss: 2.8616 - accuracy: 0.6080 - val_loss: 2.9344 - val_accuracy: 0.6042\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 2.8475 - accuracy: 0.6049 - val_loss: 2.9317 - val_accuracy: 0.6033\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 181s 2s/step - loss: 2.8587 - accuracy: 0.6057 - val_loss: 2.9141 - val_accuracy: 0.6024\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 182s 3s/step - loss: 2.8838 - accuracy: 0.6034 - val_loss: 2.9260 - val_accuracy: 0.5977\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 184s 3s/step - loss: 2.8683 - accuracy: 0.6060 - val_loss: 2.9558 - val_accuracy: 0.5994\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 184s 3s/step - loss: 2.8556 - accuracy: 0.6068 - val_loss: 2.9335 - val_accuracy: 0.6042\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 181s 2s/step - loss: 2.8359 - accuracy: 0.6132 - val_loss: 2.9197 - val_accuracy: 0.6007\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 2.8262 - accuracy: 0.6098 - val_loss: 2.9222 - val_accuracy: 0.6059\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 181s 2s/step - loss: 2.8322 - accuracy: 0.6076 - val_loss: 2.9365 - val_accuracy: 0.5998\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 184s 3s/step - loss: 2.8306 - accuracy: 0.6074 - val_loss: 2.9759 - val_accuracy: 0.5890\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 2.8253 - accuracy: 0.6086 - val_loss: 2.9623 - val_accuracy: 0.5998\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 181s 2s/step - loss: 2.8226 - accuracy: 0.6163 - val_loss: 2.9173 - val_accuracy: 0.6029\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 180s 2s/step - loss: 2.8080 - accuracy: 0.6160 - val_loss: 2.9004 - val_accuracy: 0.6076\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 180s 2s/step - loss: 2.7975 - accuracy: 0.6158 - val_loss: 2.9418 - val_accuracy: 0.6020\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 2.8223 - accuracy: 0.6130 - val_loss: 2.9253 - val_accuracy: 0.6046\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 2.7990 - accuracy: 0.6166 - val_loss: 2.9206 - val_accuracy: 0.5972\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 183s 3s/step - loss: 2.8227 - accuracy: 0.6105 - val_loss: 2.9227 - val_accuracy: 0.6024\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 181s 2s/step - loss: 2.7765 - accuracy: 0.6192 - val_loss: 2.9048 - val_accuracy: 0.6033\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 180s 2s/step - loss: 2.7830 - accuracy: 0.6203 - val_loss: 2.8794 - val_accuracy: 0.6146\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 180s 2s/step - loss: 2.7739 - accuracy: 0.6186 - val_loss: 2.8790 - val_accuracy: 0.6085\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 183s 3s/step - loss: 2.7581 - accuracy: 0.6228 - val_loss: 2.8834 - val_accuracy: 0.6137\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 182s 2s/step - loss: 2.7848 - accuracy: 0.6177 - val_loss: 2.9070 - val_accuracy: 0.5977\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 180s 2s/step - loss: 2.7665 - accuracy: 0.6258 - val_loss: 2.8697 - val_accuracy: 0.6115\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 180s 2s/step - loss: 2.7588 - accuracy: 0.6223 - val_loss: 2.8479 - val_accuracy: 0.6120\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 181s 2s/step - loss: 2.7552 - accuracy: 0.6223 - val_loss: 2.8562 - val_accuracy: 0.6115\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2d261510d0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "#AFTER COMPILING THE MODEL, THE MODEL IS TRAINED BELOW\n",
        "callbacks = [\n",
        "    # tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True,),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs/GoogleNetlog1' , histogram_freq=1),\n",
        "    # tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=3, verbose=1, min_delta=0.0001, min_lr=1e-5, ),\n",
        "    \n",
        "]\n",
        "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n",
        "STEP_SIZE_TEST = test_generator.n//test_generator.batch_size\n",
        "\n",
        "model1.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,  validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=100, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4g8dG_-h7ZaD"
      },
      "outputs": [],
      "source": [
        "model1.save(\"models/GoogleNet-model1.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lDdIWgyTDtS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a6a364a-59b4-418b-ed53-d6fe41d0e3b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "new_model1 = keras.models.load_model(\"models/GoogleNet-model1.h5\", compile=False)\n",
        "prob1 = model1.predict_generator(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TG1s94swTDa1"
      },
      "outputs": [],
      "source": [
        "roc_auc_score(test_label[:, 0], prob1[:, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfmMKi0RSuFi"
      },
      "outputs": [],
      "source": [
        "roc_auc_score(test_label[:, 1], prob1[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85xsFfugSt3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55d249c2-2730-4257-c730-523c300b1c1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5791766652984329"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "roc_auc_score(test_label[:, 2], prob1[:, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M53SMxO4StrM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e98a69e2-af1f-4100-d3e4-e87269792a02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6995390799073791"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "roc_auc_score(test_label[:, 3], prob1[:, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVwj_YPyTwxN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAcFoYhmTwoA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLGXUj2RTwgm"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "GoogleNet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}